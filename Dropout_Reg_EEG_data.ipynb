{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62fcf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b08aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183932</th>\n",
       "      <td>1.62880</td>\n",
       "      <td>0.44829</td>\n",
       "      <td>1.62730</td>\n",
       "      <td>4.27350</td>\n",
       "      <td>7.19210</td>\n",
       "      <td>-1.60220</td>\n",
       "      <td>3.60370</td>\n",
       "      <td>3.48250</td>\n",
       "      <td>3.04450</td>\n",
       "      <td>-3.023800</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.790700</td>\n",
       "      <td>-1.261600</td>\n",
       "      <td>0.21643</td>\n",
       "      <td>-0.51546</td>\n",
       "      <td>-2.792700</td>\n",
       "      <td>2.0996</td>\n",
       "      <td>1.33130</td>\n",
       "      <td>1.672900</td>\n",
       "      <td>2.24880</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125679</th>\n",
       "      <td>0.36583</td>\n",
       "      <td>1.24430</td>\n",
       "      <td>-0.84785</td>\n",
       "      <td>-4.51700</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>5.65680</td>\n",
       "      <td>-2.55690</td>\n",
       "      <td>-5.35390</td>\n",
       "      <td>-5.47700</td>\n",
       "      <td>-2.927200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>3.414600</td>\n",
       "      <td>2.18120</td>\n",
       "      <td>-0.54694</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>3.1541</td>\n",
       "      <td>-2.73000</td>\n",
       "      <td>-0.701280</td>\n",
       "      <td>-3.95850</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140036</th>\n",
       "      <td>-4.61780</td>\n",
       "      <td>-4.23330</td>\n",
       "      <td>-1.83310</td>\n",
       "      <td>1.17490</td>\n",
       "      <td>-0.11087</td>\n",
       "      <td>-4.18240</td>\n",
       "      <td>0.88512</td>\n",
       "      <td>9.78340</td>\n",
       "      <td>5.83530</td>\n",
       "      <td>2.264400</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.878800</td>\n",
       "      <td>-4.002100</td>\n",
       "      <td>-0.45293</td>\n",
       "      <td>-0.84502</td>\n",
       "      <td>-1.903100</td>\n",
       "      <td>-3.4057</td>\n",
       "      <td>-0.98300</td>\n",
       "      <td>-1.875100</td>\n",
       "      <td>0.76578</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192583</th>\n",
       "      <td>-0.66212</td>\n",
       "      <td>-1.10550</td>\n",
       "      <td>-1.62410</td>\n",
       "      <td>-2.64510</td>\n",
       "      <td>0.69823</td>\n",
       "      <td>-0.99559</td>\n",
       "      <td>-0.12163</td>\n",
       "      <td>-1.06790</td>\n",
       "      <td>2.44510</td>\n",
       "      <td>2.581200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.754500</td>\n",
       "      <td>-0.849850</td>\n",
       "      <td>0.69272</td>\n",
       "      <td>2.00310</td>\n",
       "      <td>1.882100</td>\n",
       "      <td>2.1965</td>\n",
       "      <td>1.63520</td>\n",
       "      <td>3.399800</td>\n",
       "      <td>0.70771</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212280</th>\n",
       "      <td>-2.75420</td>\n",
       "      <td>-3.11940</td>\n",
       "      <td>-3.37610</td>\n",
       "      <td>-1.16490</td>\n",
       "      <td>2.42090</td>\n",
       "      <td>-0.26762</td>\n",
       "      <td>1.26490</td>\n",
       "      <td>1.55900</td>\n",
       "      <td>4.85930</td>\n",
       "      <td>-0.768810</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.286700</td>\n",
       "      <td>0.684640</td>\n",
       "      <td>2.92920</td>\n",
       "      <td>1.01190</td>\n",
       "      <td>-0.693080</td>\n",
       "      <td>1.3059</td>\n",
       "      <td>-0.44038</td>\n",
       "      <td>-0.024312</td>\n",
       "      <td>-1.74360</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277626</th>\n",
       "      <td>3.76940</td>\n",
       "      <td>4.29980</td>\n",
       "      <td>5.21500</td>\n",
       "      <td>1.88710</td>\n",
       "      <td>-0.82971</td>\n",
       "      <td>2.89110</td>\n",
       "      <td>-0.31320</td>\n",
       "      <td>0.50743</td>\n",
       "      <td>-2.60340</td>\n",
       "      <td>-2.347700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>-0.039959</td>\n",
       "      <td>-2.08790</td>\n",
       "      <td>-1.34630</td>\n",
       "      <td>-0.063717</td>\n",
       "      <td>-3.3120</td>\n",
       "      <td>-2.33920</td>\n",
       "      <td>-4.480400</td>\n",
       "      <td>-5.68050</td>\n",
       "      <td>LV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191013</th>\n",
       "      <td>2.95530</td>\n",
       "      <td>2.79650</td>\n",
       "      <td>2.81230</td>\n",
       "      <td>1.13320</td>\n",
       "      <td>1.87900</td>\n",
       "      <td>1.51160</td>\n",
       "      <td>2.64810</td>\n",
       "      <td>2.76590</td>\n",
       "      <td>0.73598</td>\n",
       "      <td>2.482100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263880</td>\n",
       "      <td>-2.257000</td>\n",
       "      <td>-1.79790</td>\n",
       "      <td>-1.03320</td>\n",
       "      <td>-0.703450</td>\n",
       "      <td>-1.5122</td>\n",
       "      <td>-3.98640</td>\n",
       "      <td>-1.961300</td>\n",
       "      <td>-2.38200</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268043</th>\n",
       "      <td>-2.19410</td>\n",
       "      <td>-5.38050</td>\n",
       "      <td>-7.64110</td>\n",
       "      <td>-0.88071</td>\n",
       "      <td>0.12721</td>\n",
       "      <td>-1.50380</td>\n",
       "      <td>-4.60290</td>\n",
       "      <td>-6.80980</td>\n",
       "      <td>-3.19500</td>\n",
       "      <td>-0.026346</td>\n",
       "      <td>...</td>\n",
       "      <td>3.021100</td>\n",
       "      <td>5.229900</td>\n",
       "      <td>8.12160</td>\n",
       "      <td>5.60750</td>\n",
       "      <td>4.784600</td>\n",
       "      <td>6.2092</td>\n",
       "      <td>5.90130</td>\n",
       "      <td>5.461200</td>\n",
       "      <td>3.61030</td>\n",
       "      <td>LV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60166</th>\n",
       "      <td>8.49160</td>\n",
       "      <td>9.10430</td>\n",
       "      <td>10.55700</td>\n",
       "      <td>11.66100</td>\n",
       "      <td>4.61710</td>\n",
       "      <td>-3.44550</td>\n",
       "      <td>-2.27260</td>\n",
       "      <td>7.74870</td>\n",
       "      <td>-2.04980</td>\n",
       "      <td>-10.322000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.179400</td>\n",
       "      <td>-7.244900</td>\n",
       "      <td>3.52110</td>\n",
       "      <td>1.97790</td>\n",
       "      <td>-9.130200</td>\n",
       "      <td>-6.4053</td>\n",
       "      <td>7.75030</td>\n",
       "      <td>-3.840200</td>\n",
       "      <td>2.67150</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74146</th>\n",
       "      <td>-0.36048</td>\n",
       "      <td>0.44417</td>\n",
       "      <td>0.60004</td>\n",
       "      <td>-4.36980</td>\n",
       "      <td>-2.45950</td>\n",
       "      <td>2.43670</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>-5.41270</td>\n",
       "      <td>-2.23170</td>\n",
       "      <td>0.901090</td>\n",
       "      <td>...</td>\n",
       "      <td>1.492200</td>\n",
       "      <td>-0.286970</td>\n",
       "      <td>-2.51790</td>\n",
       "      <td>-0.82684</td>\n",
       "      <td>0.760230</td>\n",
       "      <td>2.8246</td>\n",
       "      <td>0.98379</td>\n",
       "      <td>4.218300</td>\n",
       "      <td>4.81200</td>\n",
       "      <td>LV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1         2         3        4        5        6   \\\n",
       "183932  1.62880  0.44829   1.62730   4.27350  7.19210 -1.60220  3.60370   \n",
       "125679  0.36583  1.24430  -0.84785  -4.51700  0.06141  5.65680 -2.55690   \n",
       "140036 -4.61780 -4.23330  -1.83310   1.17490 -0.11087 -4.18240  0.88512   \n",
       "192583 -0.66212 -1.10550  -1.62410  -2.64510  0.69823 -0.99559 -0.12163   \n",
       "212280 -2.75420 -3.11940  -3.37610  -1.16490  2.42090 -0.26762  1.26490   \n",
       "277626  3.76940  4.29980   5.21500   1.88710 -0.82971  2.89110 -0.31320   \n",
       "191013  2.95530  2.79650   2.81230   1.13320  1.87900  1.51160  2.64810   \n",
       "268043 -2.19410 -5.38050  -7.64110  -0.88071  0.12721 -1.50380 -4.60290   \n",
       "60166   8.49160  9.10430  10.55700  11.66100  4.61710 -3.44550 -2.27260   \n",
       "74146  -0.36048  0.44417   0.60004  -4.36980 -2.45950  2.43670  0.21350   \n",
       "\n",
       "             7        8          9   ...        23        24       25  \\\n",
       "183932  3.48250  3.04450  -3.023800  ... -3.790700 -1.261600  0.21643   \n",
       "125679 -5.35390 -5.47700  -2.927200  ...  4.115000  3.414600  2.18120   \n",
       "140036  9.78340  5.83530   2.264400  ... -1.878800 -4.002100 -0.45293   \n",
       "192583 -1.06790  2.44510   2.581200  ... -1.754500 -0.849850  0.69272   \n",
       "212280  1.55900  4.85930  -0.768810  ... -3.286700  0.684640  2.92920   \n",
       "277626  0.50743 -2.60340  -2.347700  ...  0.013557 -0.039959 -2.08790   \n",
       "191013  2.76590  0.73598   2.482100  ... -0.263880 -2.257000 -1.79790   \n",
       "268043 -6.80980 -3.19500  -0.026346  ...  3.021100  5.229900  8.12160   \n",
       "60166   7.74870 -2.04980 -10.322000  ... -7.179400 -7.244900  3.52110   \n",
       "74146  -5.41270 -2.23170   0.901090  ...  1.492200 -0.286970 -2.51790   \n",
       "\n",
       "             26        27      28       29        30       31  32  \n",
       "183932 -0.51546 -2.792700  2.0996  1.33130  1.672900  2.24880  HV  \n",
       "125679 -0.54694  0.244200  3.1541 -2.73000 -0.701280 -3.95850  HV  \n",
       "140036 -0.84502 -1.903100 -3.4057 -0.98300 -1.875100  0.76578  HV  \n",
       "192583  2.00310  1.882100  2.1965  1.63520  3.399800  0.70771  HV  \n",
       "212280  1.01190 -0.693080  1.3059 -0.44038 -0.024312 -1.74360  HV  \n",
       "277626 -1.34630 -0.063717 -3.3120 -2.33920 -4.480400 -5.68050  LV  \n",
       "191013 -1.03320 -0.703450 -1.5122 -3.98640 -1.961300 -2.38200  HV  \n",
       "268043  5.60750  4.784600  6.2092  5.90130  5.461200  3.61030  LV  \n",
       "60166   1.97790 -9.130200 -6.4053  7.75030 -3.840200  2.67150  HV  \n",
       "74146  -0.82684  0.760230  2.8246  0.98379  4.218300  4.81200  LV  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df= pd.read_csv(\"SUB1_all_trial_chan_withoutcolname - Copy.csv\",header=None)\n",
    "inp_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16856287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322560, 33)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27fe6514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "30    0\n",
       "31    0\n",
       "32    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7eaf0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51daaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LV    177408\n",
       "HV    145152\n",
       "Name: 32, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_df[32].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ffb5f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.94823</td>\n",
       "      <td>0.12471</td>\n",
       "      <td>-2.2165</td>\n",
       "      <td>1.00570</td>\n",
       "      <td>5.09590</td>\n",
       "      <td>1.206500</td>\n",
       "      <td>3.86650</td>\n",
       "      <td>1.8617</td>\n",
       "      <td>3.6890</td>\n",
       "      <td>1.3198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54868</td>\n",
       "      <td>-1.37120</td>\n",
       "      <td>-4.7267</td>\n",
       "      <td>-1.87530</td>\n",
       "      <td>-5.6503</td>\n",
       "      <td>-4.1081</td>\n",
       "      <td>-2.2701</td>\n",
       "      <td>-3.5572</td>\n",
       "      <td>-1.23730</td>\n",
       "      <td>0.37227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.65330</td>\n",
       "      <td>1.39010</td>\n",
       "      <td>2.2920</td>\n",
       "      <td>1.29790</td>\n",
       "      <td>5.00090</td>\n",
       "      <td>0.599490</td>\n",
       "      <td>3.28000</td>\n",
       "      <td>7.1906</td>\n",
       "      <td>4.7010</td>\n",
       "      <td>-3.8532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13791</td>\n",
       "      <td>-4.65310</td>\n",
       "      <td>-8.1813</td>\n",
       "      <td>-4.46540</td>\n",
       "      <td>-6.2474</td>\n",
       "      <td>-5.3078</td>\n",
       "      <td>-3.8337</td>\n",
       "      <td>-1.2603</td>\n",
       "      <td>-0.94138</td>\n",
       "      <td>2.07620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.01370</td>\n",
       "      <td>1.83510</td>\n",
       "      <td>2.7464</td>\n",
       "      <td>2.36770</td>\n",
       "      <td>4.17620</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.65637</td>\n",
       "      <td>5.9065</td>\n",
       "      <td>1.7129</td>\n",
       "      <td>-6.4447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25227</td>\n",
       "      <td>-4.51990</td>\n",
       "      <td>-6.8561</td>\n",
       "      <td>-4.63900</td>\n",
       "      <td>-7.3880</td>\n",
       "      <td>-4.7433</td>\n",
       "      <td>-2.9737</td>\n",
       "      <td>-3.0996</td>\n",
       "      <td>1.02800</td>\n",
       "      <td>4.46520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.49510</td>\n",
       "      <td>-1.11070</td>\n",
       "      <td>-2.3645</td>\n",
       "      <td>-0.23185</td>\n",
       "      <td>0.35406</td>\n",
       "      <td>1.974200</td>\n",
       "      <td>-3.07740</td>\n",
       "      <td>-3.6535</td>\n",
       "      <td>-4.3127</td>\n",
       "      <td>-5.4696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68571</td>\n",
       "      <td>-0.13215</td>\n",
       "      <td>-1.7430</td>\n",
       "      <td>0.12154</td>\n",
       "      <td>-3.7701</td>\n",
       "      <td>-1.4081</td>\n",
       "      <td>1.5551</td>\n",
       "      <td>-1.5860</td>\n",
       "      <td>4.05470</td>\n",
       "      <td>5.91790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.26480</td>\n",
       "      <td>-2.59060</td>\n",
       "      <td>-2.3095</td>\n",
       "      <td>-1.66240</td>\n",
       "      <td>-4.15410</td>\n",
       "      <td>-0.091352</td>\n",
       "      <td>-2.85770</td>\n",
       "      <td>-1.0455</td>\n",
       "      <td>-4.3779</td>\n",
       "      <td>-2.5544</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.60540</td>\n",
       "      <td>1.83910</td>\n",
       "      <td>1.2470</td>\n",
       "      <td>2.41740</td>\n",
       "      <td>2.8298</td>\n",
       "      <td>1.1041</td>\n",
       "      <td>2.6442</td>\n",
       "      <td>3.8879</td>\n",
       "      <td>3.61610</td>\n",
       "      <td>4.85800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1       2        3        4         5        6       7   \\\n",
       "0  0.94823  0.12471 -2.2165  1.00570  5.09590  1.206500  3.86650  1.8617   \n",
       "1  1.65330  1.39010  2.2920  1.29790  5.00090  0.599490  3.28000  7.1906   \n",
       "2  3.01370  1.83510  2.7464  2.36770  4.17620  0.869300  0.65637  5.9065   \n",
       "3  1.49510 -1.11070 -2.3645 -0.23185  0.35406  1.974200 -3.07740 -3.6535   \n",
       "4 -1.26480 -2.59060 -2.3095 -1.66240 -4.15410 -0.091352 -2.85770 -1.0455   \n",
       "\n",
       "       8       9   ...       22       23      24       25      26      27  \\\n",
       "0  3.6890  1.3198  ... -0.54868 -1.37120 -4.7267 -1.87530 -5.6503 -4.1081   \n",
       "1  4.7010 -3.8532  ... -0.13791 -4.65310 -8.1813 -4.46540 -6.2474 -5.3078   \n",
       "2  1.7129 -6.4447  ... -0.25227 -4.51990 -6.8561 -4.63900 -7.3880 -4.7433   \n",
       "3 -4.3127 -5.4696  ...  0.68571 -0.13215 -1.7430  0.12154 -3.7701 -1.4081   \n",
       "4 -4.3779 -2.5544  ... -1.60540  1.83910  1.2470  2.41740  2.8298  1.1041   \n",
       "\n",
       "       28      29       30       31  \n",
       "0 -2.2701 -3.5572 -1.23730  0.37227  \n",
       "1 -3.8337 -1.2603 -0.94138  2.07620  \n",
       "2 -2.9737 -3.0996  1.02800  4.46520  \n",
       "3  1.5551 -1.5860  4.05470  5.91790  \n",
       "4  2.6442  3.8879  3.61610  4.85800  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create X(Independent Variables) and Y(Dependent Variable)\n",
    "\n",
    "X_ind= inp_df.drop(32,axis=1)\n",
    "Y_dep= inp_df[32]\n",
    "X_ind.head()\n",
    "#Y_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c91c91db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LV\n",
       "0   0\n",
       "1   0\n",
       "2   0\n",
       "3   0\n",
       "4   0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-Hot-Encoding of Y_dep\n",
    "\n",
    "Y_dep=pd.get_dummies(Y_dep,drop_first=True)\n",
    "Y_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e8e3426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LV\n",
       "1     177408\n",
       "0     145152\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_dep.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5305197e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((225792, 32), (96768, 32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(X_ind,Y_dep,test_size=0.3,random_state=1)\n",
    "X_Train.shape,X_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92a20f6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22580/22580 [==============================] - 25s 1ms/step - loss: 0.6892 - accuracy: 0.5489A: 22s - loss: 0.6979 - accu - ETA: 21s - los - ETA: 16s - loss: 0. - ETA: 14s - loss: 0.6908 - accuracy: - E - ETA: 2s - loss: 0.6893 - accuracy:  - ETA: 0s - loss: 0.6891 -  - ETA: 0s - loss: 0.6892 - \n",
      "Epoch 2/50\n",
      "22580/22580 [==============================] - 25s 1ms/step - loss: 0.6880 - accuracy: 0.5503A\n",
      "Epoch 3/50\n",
      "22580/22580 [==============================] - 24s 1ms/step - loss: 0.6873 - accuracy: 0.5503\n",
      "Epoch 4/50\n",
      "22580/22580 [==============================] - 34s 1ms/step - loss: 0.6861 - accuracy: 0.5513\n",
      "Epoch 5/50\n",
      "22580/22580 [==============================] - 31s 1ms/step - loss: 0.6839 - accuracy: 0.5561\n",
      "Epoch 6/50\n",
      "22580/22580 [==============================] - 23s 1ms/step - loss: 0.6820 - accuracy: 0.5609A: 25s - loss: 0.6803 - accuracy:  - ET - ETA: 2s\n",
      "Epoch 7/50\n",
      "22580/22580 [==============================] - 33s 1ms/step - loss: 0.6807 - accuracy: 0.5644A:  - ETA: 1s - loss: - ETA: 0s - loss: 0.6806 - accuracy: 0.56\n",
      "Epoch 8/50\n",
      "22580/22580 [==============================] - 37s 2ms/step - loss: 0.6799 - accuracy: 0.5646\n",
      "Epoch 9/50\n",
      "22580/22580 [==============================] - 27s 1ms/step - loss: 0.6793 - accuracy: 0.5666\n",
      "Epoch 10/50\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6790 - accuracy: 0.5679\n",
      "Epoch 11/50\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6787 - accuracy: 0.5679\n",
      "Epoch 12/50\n",
      "22580/22580 [==============================] - 34s 2ms/step - loss: 0.6784 - accuracy: 0.5685 0s - loss: 0.678\n",
      "Epoch 13/50\n",
      "22580/22580 [==============================] - 33s 1ms/step - loss: 0.6779 - accuracy: 0.5700\n",
      "Epoch 14/50\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6778 - accuracy: 0.5689\n",
      "Epoch 15/50\n",
      "22580/22580 [==============================] - 24s 1ms/step - loss: 0.6773 - accuracy: 0.5708\n",
      "Epoch 16/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6770 - accuracy: 0.5716 1s - loss: - ETA: 0s - loss: 0.6770 - accuracy: 0.\n",
      "Epoch 17/50\n",
      "22580/22580 [==============================] - 31s 1ms/step - loss: 0.6768 - accuracy: 0.5723\n",
      "Epoch 18/50\n",
      "22580/22580 [==============================] - 28s 1ms/step - loss: 0.6766 - accuracy: 0.5719\n",
      "Epoch 19/50\n",
      "22580/22580 [==============================] - 39s 2ms/step - loss: 0.6765 - accuracy: 0.5720 2s - loss: 0.6766 - ac -\n",
      "Epoch 20/50\n",
      "22580/22580 [==============================] - 33s 1ms/step - loss: 0.6763 - accuracy: 0.5714\n",
      "Epoch 21/50\n",
      "22580/22580 [==============================] - 34s 1ms/step - loss: 0.6761 - accuracy: 0.5724 1s - loss: 0.6760 - accura - ETA: 0s - loss: 0.6\n",
      "Epoch 22/50\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6760 - accuracy: 0.5725 1s - l\n",
      "Epoch 23/50\n",
      "22580/22580 [==============================] - 34s 1ms/step - loss: 0.6758 - accuracy: 0.5723 0s - loss: 0.6758 - accuracy: \n",
      "Epoch 24/50\n",
      "22580/22580 [==============================] - 33s 1ms/step - loss: 0.6757 - accuracy: 0.5731\n",
      "Epoch 25/50\n",
      "22580/22580 [==============================] - 34s 1ms/step - loss: 0.6755 - accuracy: 0.5740 1s - loss: 0\n",
      "Epoch 26/50\n",
      "22580/22580 [==============================] - 30s 1ms/step - loss: 0.6753 - accuracy: 0.5739\n",
      "Epoch 27/50\n",
      "22580/22580 [==============================] - 30s 1ms/step - loss: 0.6751 - accuracy: 0.5747 5s - loss: 0.6749 - accu - ETA: 4s - loss: 0.6750 - accura - ETA: 4s - loss: 0.674\n",
      "Epoch 28/50\n",
      "22580/22580 [==============================] - 39s 2ms/step - loss: 0.6751 - accuracy: 0.5739\n",
      "Epoch 29/50\n",
      "22580/22580 [==============================] - 30s 1ms/step - loss: 0.6749 - accuracy: 0.5742\n",
      "Epoch 30/50\n",
      "22580/22580 [==============================] - 38s 2ms/step - loss: 0.6749 - accuracy: 0.5745\n",
      "Epoch 31/50\n",
      "22580/22580 [==============================] - 34s 2ms/step - loss: 0.6746 - accuracy: 0.5752\n",
      "Epoch 32/50\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6745 - accuracy: 0.5755\n",
      "Epoch 33/50\n",
      "22580/22580 [==============================] - 24s 1ms/step - loss: 0.6746 - accuracy: 0.5754\n",
      "Epoch 34/50\n",
      "22580/22580 [==============================] - 37s 2ms/step - loss: 0.6745 - accuracy: 0.5753\n",
      "Epoch 35/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6744 - accuracy: 0.5743\n",
      "Epoch 36/50\n",
      "22580/22580 [==============================] - 26s 1ms/step - loss: 0.6742 - accuracy: 0.5758\n",
      "Epoch 37/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6741 - accuracy: 0.5754A: 24s - loss: 0.6733 - a\n",
      "Epoch 38/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6740 - accuracy: 0.5759\n",
      "Epoch 39/50\n",
      "22580/22580 [==============================] - 25s 1ms/step - loss: 0.6740 - accuracy: 0.5759\n",
      "Epoch 40/50\n",
      "22580/22580 [==============================] - 45s 2ms/step - loss: 0.6739 - accuracy: 0.5764A: 13s - loss: 0.6739 - accuracy: 0.57 - ETA: 12s - loss: 0.6739 - ac - ETA: 10s -  - ETA: 5s - loss: 0.6741 - ac - ETA: 4s - loss: 0.6 - ETA: 0s - loss: 0.6739 - accuracy\n",
      "Epoch 41/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6738 - accuracy: 0.5760\n",
      "Epoch 42/50\n",
      "22580/22580 [==============================] - 38s 2ms/step - loss: 0.6738 - accuracy: 0.5766\n",
      "Epoch 43/50\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6737 - accuracy: 0.5766\n",
      "Epoch 44/50\n",
      "22580/22580 [==============================] - 31s 1ms/step - loss: 0.6736 - accuracy: 0.5772 0s - loss: 0.6736 - \n",
      "Epoch 45/50\n",
      "22580/22580 [==============================] - 41s 2ms/step - loss: 0.6735 - accuracy: 0.5763A: 16s - loss: - ETA: 5s - loss: 0.673\n",
      "Epoch 46/50\n",
      "22580/22580 [==============================] - 34s 2ms/step - loss: 0.6735 - accuracy: 0.5763\n",
      "Epoch 47/50\n",
      "22580/22580 [==============================] - 45s 2ms/step - loss: 0.6736 - accuracy: 0.5762 0s - loss: 0.6736 - \n",
      "Epoch 48/50\n",
      "22580/22580 [==============================] - 37s 2ms/step - loss: 0.6734 - accuracy: 0.5776 1s - los\n",
      "Epoch 49/50\n",
      "22580/22580 [==============================] - 48s 2ms/step - loss: 0.6734 - accuracy: 0.5762\n",
      "Epoch 50/50\n",
      "22580/22580 [==============================] - 45s 2ms/step - loss: 0.6731 - accuracy: 0.5777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ac4eadee0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create ANN\n",
    "\n",
    "EEG_model=keras.Sequential([\n",
    "    \n",
    "    keras.layers.Dense(32,input_dim=32,activation='relu'),\n",
    "    \n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    \n",
    "    keras.layers.Dense(8,activation='relu'),\n",
    "    \n",
    "    keras.layers.Dense(1,activation='sigmoid'),\n",
    "])\n",
    "\n",
    "#Model Compilation\n",
    "\n",
    "\n",
    "EEG_model.compile(loss ='binary_crossentropy',\n",
    "                 optimizer ='adam',\n",
    "                 metrics =['accuracy'])\n",
    "\n",
    "\n",
    "#Model Training\n",
    "\n",
    "EEG_model.fit(X_Train,Y_Train, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "570e64c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3024/3024 [==============================] - 3s 866us/step - loss: 0.6787 - accuracy: 0.5668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6787227392196655, 0.5668402910232544]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEG_model.evaluate(X_Test,Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6cadade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57452184 0.6051985  0.5088729  0.55169815 0.47510964 0.3495494\n",
      " 0.2847098  0.5576788  0.5693852  0.5983826  0.5246316  0.48644742\n",
      " 0.56930304 0.5691428  0.563446   0.5420534  0.5709787  0.57452184\n",
      " 0.5452977  0.51991135]\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "\n",
    "Y_Pred=EEG_model.predict(X_Test).reshape(-1)\n",
    "print(Y_Pred[:20])\n",
    "\n",
    "Y_Pred=np.round(Y_Pred)\n",
    "print(Y_Pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c5f0718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241913</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99093</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151918</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65511</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66927</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193463</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230805</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144934</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113126</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83969</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287047</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41111</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113754</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64405</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214150</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171733</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261930</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209807</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43655</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LV\n",
       "241913   1\n",
       "99093    1\n",
       "3395     0\n",
       "151918   0\n",
       "65511    1\n",
       "66927    1\n",
       "193463   0\n",
       "230805   1\n",
       "144934   0\n",
       "113126   1\n",
       "83969    1\n",
       "287047   1\n",
       "41111    0\n",
       "113754   1\n",
       "64405    0\n",
       "214150   0\n",
       "171733   0\n",
       "261930   1\n",
       "209807   0\n",
       "43655    0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "badc58a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.22      0.32     43609\n",
      "           1       0.57      0.85      0.68     53159\n",
      "\n",
      "    accuracy                           0.57     96768\n",
      "   macro avg       0.56      0.54      0.50     96768\n",
      "weighted avg       0.56      0.57      0.52     96768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_Test,Y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d7a3197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22580/22580 [==============================] - 29s 1ms/step - loss: 0.6993 - accuracy: 0.5486\n",
      "Epoch 2/10\n",
      "22580/22580 [==============================] - 40s 2ms/step - loss: 0.6882 - accuracy: 0.5501\n",
      "Epoch 3/10\n",
      "22580/22580 [==============================] - 41s 2ms/step - loss: 0.6882 - accuracy: 0.5502\n",
      "Epoch 4/10\n",
      "22580/22580 [==============================] - 41s 2ms/step - loss: 0.6882 - accuracy: 0.5503\n",
      "Epoch 5/10\n",
      "22580/22580 [==============================] - 53s 2ms/step - loss: 0.6882 - accuracy: 0.5502\n",
      "Epoch 6/10\n",
      "22580/22580 [==============================] - 61s 3ms/step - loss: 0.6882 - accuracy: 0.5502\n",
      "Epoch 7/10\n",
      "22580/22580 [==============================] - 40s 2ms/step - loss: 0.6882 - accuracy: 0.5503\n",
      "Epoch 8/10\n",
      "22580/22580 [==============================] - 35s 2ms/step - loss: 0.6881 - accuracy: 0.5502 0s - loss: 0.6881 - ac\n",
      "Epoch 9/10\n",
      "22580/22580 [==============================] - 36s 2ms/step - loss: 0.6881 - accuracy: 0.5503 0s - loss: 0.6881 - accura\n",
      "Epoch 10/10\n",
      "22580/22580 [==============================] - 42s 2ms/step - loss: 0.6881 - accuracy: 0.5502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ac5187eb0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EEG_model=keras.Sequential([\n",
    "    \n",
    "    keras.layers.Dense(32,input_dim=32,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1,activation='sigmoid'),\n",
    "])\n",
    "\n",
    "#Model Compilation\n",
    "\n",
    "\n",
    "EEG_model.compile(loss ='binary_crossentropy',\n",
    "                 optimizer ='adam',\n",
    "                 metrics =['accuracy'])\n",
    "\n",
    "\n",
    "#Model Training\n",
    "\n",
    "EEG_model.fit(X_Train,Y_Train, epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73513702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
